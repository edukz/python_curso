#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Exercise Integration - Integra√ß√£o do Code Review com sistema de exerc√≠cios
"""

from typing import Dict, List, Any, Optional, Tuple
from .analysis_engine import CodeAnalysisEngine
import json


class ExerciseCodeReviewer:
    """Integra code review com exerc√≠cios do curso"""
    
    def __init__(self, analysis_engine: CodeAnalysisEngine, progress_manager):
        self.engine = analysis_engine
        self.progress = progress_manager
        self.exercise_standards = self._load_exercise_standards()
        
    def review_exercise_solution(self, code: str, exercise_id: str, 
                               module_id: str) -> Dict[str, Any]:
        """
        Revisa solu√ß√£o de exerc√≠cio com contexto espec√≠fico
        
        Args:
            code: C√≥digo do aluno
            exercise_id: ID do exerc√≠cio
            module_id: ID do m√≥dulo
            
        Returns:
            Resultado da an√°lise com feedback espec√≠fico do exerc√≠cio
        """
        # An√°lise padr√£o
        result = self.engine.analyze_code(
            code, 
            f"{module_id}_{exercise_id}.py", 
            f"exercise_{module_id}"
        )
        
        # Adiciona feedback espec√≠fico do exerc√≠cio
        exercise_feedback = self._generate_exercise_feedback(
            result, exercise_id, module_id
        )
        
        # Adiciona ao resultado
        result['exercise_feedback'] = exercise_feedback
        result['learning_points'] = self._calculate_learning_points(result, exercise_id)
        result['next_steps'] = self._suggest_next_steps(result, module_id)
        
        # Atualiza progresso se score for suficiente
        if result['quality_score']['overall_score'] >= 70:
            self._update_exercise_progress(exercise_id, module_id, result)
        
        return result
    
    def review_mini_project(self, code: str, project_id: str) -> Dict[str, Any]:
        """Revisa mini projeto com crit√©rios espec√≠ficos"""
        result = self.engine.analyze_code(
            code,
            f"mini_project_{project_id}.py",
            "mini_project"
        )
        
        # Feedback espec√≠fico de projeto
        project_feedback = self._generate_project_feedback(result, project_id)
        
        result['project_feedback'] = project_feedback
        result['project_score'] = self._calculate_project_score(result)
        result['portfolio_ready'] = result['quality_score']['overall_score'] >= 80
        
        return result
    
    def get_exercise_hints(self, code: str, exercise_id: str) -> List[str]:
        """Gera dicas espec√≠ficas baseadas no c√≥digo atual"""
        result = self.engine.analyze_code(code, "hint_analysis.py", "hint")
        
        hints = []
        
        # Dicas baseadas em issues
        critical_issues = [i for i in result['issues'] if i['severity'] == 'critical']
        if critical_issues:
            hints.append("üö® H√° problemas cr√≠ticos que impedem a execu√ß√£o segura")
        
        # Dicas baseadas no exerc√≠cio espec√≠fico
        exercise_hints = self._get_exercise_specific_hints(result, exercise_id)
        hints.extend(exercise_hints)
        
        # Dicas gerais de melhoria
        if result['quality_score']['style_score'] < 70:
            hints.append("üí° Revise a formata√ß√£o do c√≥digo (espa√ßos, linhas)")
        
        if result['quality_score']['logic_score'] < 70:
            hints.append("üß† Verifique a l√≥gica do seu algoritmo")
        
        if len(result['issues']) > 10:
            hints.append("üîß Muitos issues detectados - foque nas corre√ß√µes mais importantes")
        
        return hints[:5]  # M√°ximo 5 dicas
    
    def analyze_learning_progress(self, student_id: str) -> Dict[str, Any]:
        """Analisa progresso de aprendizagem via code review"""
        history = self.engine.get_analysis_history()
        
        # Filtra an√°lises do estudante (por contexto de exerc√≠cio)
        student_analyses = [
            a for a in history 
            if a['context'].startswith('exercise_') or a['context'] == 'manual'
        ]
        
        if not student_analyses:
            return {"error": "Nenhuma an√°lise encontrada"}
        
        # An√°lise de progresso
        scores_over_time = [a['quality_score']['overall_score'] for a in student_analyses]
        
        # Tend√™ncia
        if len(scores_over_time) >= 3:
            recent_avg = sum(scores_over_time[-3:]) / 3
            early_avg = sum(scores_over_time[:3]) / 3
            improvement = recent_avg - early_avg
        else:
            improvement = 0
        
        # √Åreas de for√ßa e fraqueza
        category_scores = {
            'style': [],
            'logic': [],
            'security': [],
            'performance': [],
            'maintainability': [],
            'documentation': []
        }
        
        for analysis in student_analyses[-10:]:  # √öltimas 10
            scores = analysis['quality_score']
            category_scores['style'].append(scores['style_score'])
            category_scores['logic'].append(scores['logic_score'])
            category_scores['security'].append(scores['security_score'])
            category_scores['performance'].append(scores['performance_score'])
            category_scores['maintainability'].append(scores['maintainability_score'])
            category_scores['documentation'].append(scores['documentation_score'])
        
        # M√©dias por categoria
        category_averages = {
            cat: sum(scores) / len(scores) if scores else 0
            for cat, scores in category_scores.items()
        }
        
        # Identifica pontos fortes e fracos
        strengths = [cat for cat, avg in category_averages.items() if avg >= 80]
        weaknesses = [cat for cat, avg in category_averages.items() if avg < 60]
        
        return {
            "total_analyses": len(student_analyses),
            "latest_score": scores_over_time[-1] if scores_over_time else 0,
            "improvement": improvement,
            "trend": "üìà" if improvement > 5 else "üìâ" if improvement < -5 else "‚û°Ô∏è",
            "category_averages": category_averages,
            "strengths": strengths,
            "weaknesses": weaknesses,
            "learning_recommendations": self._generate_learning_recommendations(
                category_averages, weaknesses
            )
        }
    
    def _generate_exercise_feedback(self, result: Dict[str, Any], 
                                  exercise_id: str, module_id: str) -> Dict[str, Any]:
        """Gera feedback espec√≠fico do exerc√≠cio"""
        feedback = {
            "exercise_id": exercise_id,
            "module_id": module_id,
            "completion_status": "completed" if result['quality_score']['overall_score'] >= 70 else "needs_improvement",
            "specific_comments": [],
            "learning_objectives_met": [],
            "areas_to_improve": []
        }
        
        # Coment√°rios espec√≠ficos baseados no m√≥dulo
        module_feedback = {
            "modulo_1": self._feedback_modulo_1,
            "modulo_2": self._feedback_modulo_2,
            "modulo_3": self._feedback_modulo_3,
            "modulo_4": self._feedback_modulo_4,
            "modulo_7": self._feedback_modulo_7,
            "modulo_8": self._feedback_modulo_8,
            "modulo_9": self._feedback_modulo_9,
            "modulo_10": self._feedback_modulo_10
        }
        
        if module_id in module_feedback:
            module_specific = module_feedback[module_id](result)
            feedback.update(module_specific)
        
        return feedback
    
    def _feedback_modulo_1(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 1 (Introdu√ß√£o)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica se usou print()
        code_lines = result.get('code', '').lower()
        if 'print(' in code_lines:
            objectives_met.append("‚úÖ Uso correto da fun√ß√£o print()")
        else:
            improvements.append("üìù Pratique o uso da fun√ß√£o print() para sa√≠da")
        
        # Verifica coment√°rios
        if result['metrics']['comment_lines'] > 0:
            objectives_met.append("‚úÖ Incluiu coment√°rios no c√≥digo")
            comments.append("üí¨ Bom uso de coment√°rios!")
        else:
            improvements.append("üí¨ Adicione coment√°rios explicativos ao c√≥digo")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    def _feedback_modulo_3(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 3 (Vari√°veis)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica naming de vari√°veis
        naming_issues = [i for i in result['issues'] if i['issue_type'] == 'naming']
        if not naming_issues:
            objectives_met.append("‚úÖ Nomes de vari√°veis seguem conven√ß√µes")
        else:
            improvements.append("üìù Melhore os nomes das vari√°veis (use snake_case)")
        
        # Verifica se h√° vari√°veis n√£o utilizadas
        unused_vars = [i for i in result['issues'] if 'never used' in i['message']]
        if unused_vars:
            improvements.append("üßπ Remova vari√°veis n√£o utilizadas")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    def _feedback_modulo_7(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 7 (Condi√ß√µes)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica uso de condicionais
        issues = result['issues']
        
        # Verifica compara√ß√µes com True/False
        bool_comparison_issues = [i for i in issues if 'comparison with' in i['message'] and ('True' in i['message'] or 'False' in i['message'])]
        if bool_comparison_issues:
            improvements.append("üîÑ Use valores booleanos diretamente (sem comparar com True/False)")
        
        # Verifica compara√ß√µes com None
        none_comparison_issues = [i for i in issues if 'None comparison' in i['message']]
        if none_comparison_issues:
            improvements.append("üîÑ Use 'is' ou 'is not' para comparar com None")
        else:
            objectives_met.append("‚úÖ Compara√ß√µes com None corretas")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    def _feedback_modulo_8(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 8 (Loops)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica efici√™ncia de loops
        performance_issues = [i for i in result['issues'] if i['issue_type'] == 'performance']
        if performance_issues:
            improvements.append("‚ö° Otimize loops para melhor performance")
        
        # Verifica complexidade
        if result['metrics']['cyclomatic_complexity'] > 8:
            improvements.append("üß† Simplifique a l√≥gica dos loops")
        else:
            objectives_met.append("‚úÖ Complexidade dos loops adequada")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    def _feedback_modulo_9(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 9 (Listas)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica uso eficiente de listas
        performance_issues = [i for i in result['issues'] if 'list comprehension' in i['message']]
        if performance_issues:
            improvements.append("üìã Use list comprehensions quando apropriado")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    def _feedback_modulo_10(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Feedback espec√≠fico para m√≥dulo 10 (Fun√ß√µes)"""
        comments = []
        objectives_met = []
        improvements = []
        
        # Verifica se h√° fun√ß√µes
        if result['metrics']['functions'] > 0:
            objectives_met.append("‚úÖ C√≥digo organizado em fun√ß√µes")
        else:
            improvements.append("üîß Organize o c√≥digo em fun√ß√µes")
        
        # Verifica documenta√ß√£o de fun√ß√µes
        doc_issues = [i for i in result['issues'] if i['issue_type'] == 'documentation' and 'function' in i['message'].lower()]
        if doc_issues:
            improvements.append("üìö Adicione docstrings √†s fun√ß√µes")
        
        # Verifica tamanho das fun√ß√µes
        long_function_issues = [i for i in result['issues'] if 'too long' in i['message']]
        if long_function_issues:
            improvements.append("‚úÇÔ∏è Divida fun√ß√µes grandes em fun√ß√µes menores")
        
        return {
            "specific_comments": comments,
            "learning_objectives_met": objectives_met,
            "areas_to_improve": improvements
        }
    
    # Placeholders para outros m√≥dulos
    def _feedback_modulo_2(self, result): return {"specific_comments": [], "learning_objectives_met": [], "areas_to_improve": []}
    def _feedback_modulo_4(self, result): return {"specific_comments": [], "learning_objectives_met": [], "areas_to_improve": []}
    
    def _generate_project_feedback(self, result: Dict[str, Any], project_id: str) -> Dict[str, Any]:
        """Gera feedback espec√≠fico para mini projeto"""
        feedback = {
            "project_id": project_id,
            "readiness_level": self._assess_project_readiness(result),
            "professional_aspects": [],
            "improvement_suggestions": [],
            "portfolio_recommendations": []
        }
        
        score = result['quality_score']['overall_score']
        
        # Avalia√ß√£o profissional
        if score >= 90:
            feedback["professional_aspects"].append("üåü C√≥digo de qualidade profissional")
        elif score >= 80:
            feedback["professional_aspects"].append("üëç C√≥digo bom para portf√≥lio")
        elif score >= 70:
            feedback["professional_aspects"].append("üìö C√≥digo funcional, mas precisa refinamento")
        
        # Sugest√µes de melhoria
        if result['quality_score']['documentation_score'] < 70:
            feedback["improvement_suggestions"].append("üìñ Melhore a documenta√ß√£o para uso profissional")
        
        if result['quality_score']['security_score'] < 80:
            feedback["improvement_suggestions"].append("üîí Corrija problemas de seguran√ßa")
        
        # Recomenda√ß√µes de portf√≥lio
        if score >= 80:
            feedback["portfolio_recommendations"].append("‚úÖ Pronto para incluir no portf√≥lio")
        else:
            feedback["portfolio_recommendations"].append("üîß Refine antes de incluir no portf√≥lio")
        
        return feedback
    
    def _assess_project_readiness(self, result: Dict[str, Any]) -> str:
        """Avalia prontid√£o do projeto"""
        score = result['quality_score']['overall_score']
        critical_issues = len([i for i in result['issues'] if i['severity'] == 'critical'])
        
        if critical_issues > 0:
            return "not_ready"
        elif score >= 85:
            return "production_ready"
        elif score >= 70:
            return "portfolio_ready"
        else:
            return "needs_improvement"
    
    def _calculate_learning_points(self, result: Dict[str, Any], exercise_id: str) -> int:
        """Calcula pontos de aprendizado baseados na qualidade"""
        base_points = 100
        score = result['quality_score']['overall_score']
        
        # Multiplicador baseado no score
        multiplier = score / 100
        
        # B√¥nus por n√£o ter issues cr√≠ticos
        critical_issues = len([i for i in result['issues'] if i['severity'] == 'critical'])
        if critical_issues == 0:
            multiplier += 0.1
        
        # B√¥nus por boa documenta√ß√£o
        if result['quality_score']['documentation_score'] > 80:
            multiplier += 0.05
        
        return int(base_points * multiplier)
    
    def _suggest_next_steps(self, result: Dict[str, Any], module_id: str) -> List[str]:
        """Sugere pr√≥ximos passos de aprendizado"""
        steps = []
        
        # Baseado na qualidade geral
        score = result['quality_score']['overall_score']
        
        if score >= 85:
            steps.append("üéØ Tente exerc√≠cios mais avan√ßados")
            steps.append("üöÄ Considere contribuir para projetos open source")
        elif score >= 70:
            steps.append("üìö Revise conceitos espec√≠ficos com issues")
            steps.append("üîÑ Refatore o c√≥digo aplicando as sugest√µes")
        else:
            steps.append("üìñ Revise a teoria do m√≥dulo")
            steps.append("üí™ Pratique exerc√≠cios b√°sicos antes de avan√ßar")
        
        # Baseado em issues espec√≠ficos
        security_issues = [i for i in result['issues'] if i['issue_type'] == 'security']
        if security_issues:
            steps.append("üîí URGENTE: Estude pr√°ticas de seguran√ßa em Python")
        
        return steps
    
    def _get_exercise_specific_hints(self, result: Dict[str, Any], exercise_id: str) -> List[str]:
        """Gera dicas espec√≠ficas do exerc√≠cio"""
        hints = []
        
        # Dicas baseadas no ID do exerc√≠cio (exemplos)
        if "calculadora" in exercise_id.lower():
            if result['metrics']['functions'] == 0:
                hints.append("üí° Organize o c√≥digo em fun√ß√µes para cada opera√ß√£o")
            
            if any("eval" in str(issue) for issue in result['issues']):
                hints.append("‚ö†Ô∏è Evite usar eval() - implemente as opera√ß√µes diretamente")
        
        elif "email" in exercise_id.lower():
            if not any("import re" in str(result) for result in [result]):
                hints.append("üìß Considere usar regex para validar emails")
        
        elif "palavra" in exercise_id.lower():
            performance_issues = [i for i in result['issues'] if i['issue_type'] == 'performance']
            if performance_issues:
                hints.append("‚ö° Use m√©todos eficientes para processar texto")
        
        return hints
    
    def _generate_learning_recommendations(self, category_averages: Dict[str, float], 
                                         weaknesses: List[str]) -> List[str]:
        """Gera recomenda√ß√µes de aprendizado personalizadas"""
        recommendations = []
        
        for weakness in weaknesses:
            if weakness == 'style':
                recommendations.append("üìè Estude PEP 8 e use ferramentas de formata√ß√£o")
            elif weakness == 'logic':
                recommendations.append("üß† Pratique algoritmos e l√≥gica de programa√ß√£o")
            elif weakness == 'security':
                recommendations.append("üîí Estude seguran√ßa em Python - √© fundamental!")
            elif weakness == 'performance':
                recommendations.append("‚ö° Aprenda sobre otimiza√ß√£o e estruturas de dados")
            elif weakness == 'maintainability':
                recommendations.append("üîß Foque em c√≥digo limpo e refatora√ß√£o")
            elif weakness == 'documentation':
                recommendations.append("üìö Pratique escrever docstrings e coment√°rios")
        
        return recommendations
    
    def _update_exercise_progress(self, exercise_id: str, module_id: str, result: Dict[str, Any]):
        """Atualiza progresso do exerc√≠cio no sistema"""
        if hasattr(self.progress, 'update_exercise_quality'):
            quality_data = {
                'exercise_id': exercise_id,
                'module_id': module_id,
                'score': result['quality_score']['overall_score'],
                'grade': result['quality_score']['grade'],
                'issues_count': len(result['issues']),
                'analysis_timestamp': result['timestamp']
            }
            self.progress.update_exercise_quality(quality_data)
    
    def _load_exercise_standards(self) -> Dict[str, Any]:
        """Carrega padr√µes espec√≠ficos por exerc√≠cio"""
        return {
            "default": {
                "min_score": 70,
                "max_complexity": 10,
                "require_functions": False,
                "require_docstrings": False
            },
            "modulo_10": {  # Fun√ß√µes
                "min_score": 75,
                "max_complexity": 8,
                "require_functions": True,
                "require_docstrings": True
            }
        }