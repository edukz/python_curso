#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
M√≥dulo 33: DevOps Completo - Docker, CI/CD e Cloud
Aprenda DevOps profissional: containeriza√ß√£o, integra√ß√£o cont√≠nua e deploy em cloud
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any, Protocol, Union
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import uuid
from ..shared.base_module import BaseModule


class Modulo33DevOps(BaseModule):
    """M√≥dulo 33: DevOps Completo - Docker, CI/CD e Cloud"""
    
    def __init__(self):
        super().__init__("modulo_33", "DevOps Completo - Docker, CI/CD e Cloud")
        self.has_mini_project = True
        self.mini_project_points = 150
    
    def execute(self) -> None:
        """Executa o m√≥dulo sobre DevOps"""
        if not self.ui or not self.progress:
            print("‚ùå Erro: Depend√™ncias n√£o configuradas para este m√≥dulo")
            self.pausar()
            return
        
        try:
            self._devops_intro()
        except Exception as e:
            self.error_handler(lambda: None)
    
    def _devops_intro(self) -> None:
        """Conte√∫do principal sobre DevOps"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("üöÄ M√ìDULO 33: DEVOPS COMPLETO - DOCKER, CI/CD E CLOUD")
        else:
            print("\n" + "="*60)
            print("üöÄ M√ìDULO 33: DEVOPS COMPLETO - DOCKER, CI/CD E CLOUD")
            print("="*60)
        
        print("üéØ DevOps √© fundamental para desenvolvimento moderno!")
        print("üõ†Ô∏è Domine as ferramentas que empresas reais usam:")
        print("‚Ä¢ üê≥ Docker para containeriza√ß√£o")
        print("‚Ä¢ ‚öôÔ∏è CI/CD para automa√ß√£o")
        print("‚Ä¢ ‚òÅÔ∏è Cloud para deploy e escala")
        print("‚Ä¢ üìä Monitoramento e observabilidade")
        print("‚Ä¢ üîí Seguran√ßa e compliance")
        print("‚Ä¢ üöÄ DevSecOps e GitOps")
        
        self.pausar()
        
        self._docker_containerization()
        self._ci_cd_pipeline()
        self._cloud_deployment()
        self._mini_projeto_devops_pipeline()
        
        # Marcar m√≥dulo como completo
        self.complete_module()
    
    def _docker_containerization(self):
        """Docker e Containeriza√ß√£o - Parte 1"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("üê≥ DOCKER E CONTAINERIZA√á√ÉO")
        
        print("üì¶ Docker revolucionou o desenvolvimento de software!")
        print("üéØ Benef√≠cios da containeriza√ß√£o:")
        print("‚Ä¢ ‚ö° Portabilidade entre ambientes")
        print("‚Ä¢ üîí Isolamento de aplica√ß√µes")
        print("‚Ä¢ üìà Escalabilidade horizontal")
        print("‚Ä¢ üöÄ Deploy r√°pido e consistente")
        print("‚Ä¢ üí∞ Otimiza√ß√£o de recursos")
        
        codigo = '''# ========================================
# DOCKER FUNDAMENTALS
# ========================================

# 1. DOCKERFILE - Receita para criar imagem
# Dockerfile para aplica√ß√£o Python Flask

FROM python:3.11-slim

# Metadados da imagem
LABEL maintainer="dev@empresa.com"
LABEL version="1.0"
LABEL description="API Python com Flask"

# Definir diret√≥rio de trabalho
WORKDIR /app

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copiar arquivos de depend√™ncias
COPY requirements.txt .

# Instalar depend√™ncias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY . .

# Criar usu√°rio n√£o-root (seguran√ßa)
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expor porta da aplica√ß√£o
EXPOSE 5000

# Comando para executar a aplica√ß√£o
CMD ["python", "app.py"]

# ========================================
# APLICA√á√ÉO FLASK EXEMPLO
# ========================================

# app.py
from flask import Flask, jsonify, request
import os
import redis
import json
from datetime import datetime
import logging

app = Flask(__name__)

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Conectar ao Redis (se dispon√≠vel)
try:
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        decode_responses=True
    )
    redis_client.ping()
    logger.info("‚úÖ Conectado ao Redis")
except:
    redis_client = None
    logger.warning("‚ö†Ô∏è Redis n√£o dispon√≠vel")

@app.route('/health')
def health_check():
    """Endpoint para verifica√ß√£o de sa√∫de"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'redis': 'connected' if redis_client else 'disconnected'
    })

@app.route('/api/users', methods=['GET'])
def get_users():
    """API para listar usu√°rios"""
    if redis_client:
        # Tentar buscar do cache
        cached_users = redis_client.get('users')
        if cached_users:
            return jsonify(json.loads(cached_users))
    
    # Dados mock para exemplo
    users = [
        {'id': 1, 'name': 'Jo√£o Silva', 'email': 'joao@email.com'},
        {'id': 2, 'name': 'Maria Santos', 'email': 'maria@email.com'},
        {'id': 3, 'name': 'Pedro Lima', 'email': 'pedro@email.com'}
    ]
    
    # Salvar no cache (se dispon√≠vel)
    if redis_client:
        redis_client.setex('users', 300, json.dumps(users))
    
    return jsonify(users)

@app.route('/api/metrics')
def get_metrics():
    """Endpoint para m√©tricas da aplica√ß√£o"""
    import psutil
    
    return jsonify({
        'cpu_percent': psutil.cpu_percent(),
        'memory_percent': psutil.virtual_memory().percent,
        'disk_usage': psutil.disk_usage('/').percent,
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)

# ========================================
# REQUIREMENTS.TXT
# ========================================
"""
Flask==2.3.2
redis==4.6.0
psutil==5.9.5
gunicorn==21.2.0
"""

# ========================================
# DOCKER COMPOSE - ORQUESTRA√á√ÉO DE CONTAINERS
# ========================================

# docker-compose.yml
version: '3.8'

services:
  # Servi√ßo da aplica√ß√£o Python
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PORT=5000
    depends_on:
      - redis
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
    networks:
      - app-network

  # Servi√ßo Redis para cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - app-network

  # Nginx como proxy reverso
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - web
    restart: unless-stopped
    networks:
      - app-network

  # Monitoramento com Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - app-network

volumes:
  redis_data:

networks:
  app-network:
    driver: bridge

# ========================================
# COMANDOS DOCKER ESSENCIAIS
# ========================================

# Construir imagem
docker build -t minha-app:1.0 .

# Executar container
docker run -d -p 5000:5000 --name minha-app minha-app:1.0

# Ver containers rodando
docker ps

# Ver logs do container
docker logs minha-app

# Executar comando dentro do container
docker exec -it minha-app bash

# Parar container
docker stop minha-app

# Remover container
docker rm minha-app

# Usar Docker Compose
docker-compose up -d
docker-compose logs -f
docker-compose down

# ========================================
# CONFIGURA√á√ÉO NGINX
# ========================================

# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream webapp {
        server web:5000;
    }

    server {
        listen 80;
        
        location / {
            proxy_pass http://webapp;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        
        location /health {
            proxy_pass http://webapp/health;
        }
    }
}

print("üê≥ DOCKER EM A√á√ÉO:")
print("1. Dockerfile define a imagem")
print("2. Docker Compose orquestra m√∫ltiplos containers")
print("3. Nginx como proxy reverso")
print("4. Redis para cache e sess√µes")
print("5. Prometheus para monitoramento")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _ci_cd_pipeline(self):
        """CI/CD Pipeline - Parte 2"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("‚öôÔ∏è CI/CD - INTEGRA√á√ÉO E ENTREGA CONT√çNUA")
        
        print("üîÑ CI/CD automatiza todo o ciclo de desenvolvimento!")
        print("üéØ Benef√≠cios da automa√ß√£o:")
        print("‚Ä¢ ‚ú® Testes autom√°ticos a cada commit")
        print("‚Ä¢ üöÄ Deploy autom√°tico em produ√ß√£o")
        print("‚Ä¢ üîí Verifica√ß√µes de seguran√ßa")
        print("‚Ä¢ üìä Qualidade de c√≥digo garantida")
        print("‚Ä¢ ‚ö° Feedback r√°pido para desenvolvedores")
        
        codigo = '''# ========================================
# GITHUB ACTIONS - CI/CD PIPELINE
# ========================================

# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ========================================
  # JOB 1: TESTES E QUALIDADE DE C√ìDIGO
  # ========================================
  test:
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: üì• Checkout do c√≥digo
      uses: actions/checkout@v3

    - name: üêç Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: üì¶ Instalar depend√™ncias
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black isort safety bandit

    - name: üßπ Verificar formata√ß√£o (Black)
      run: black --check .

    - name: üìù Verificar importa√ß√µes (isort)
      run: isort --check-only .

    - name: üîç An√°lise est√°tica (Flake8)
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

    - name: üîí Verificar vulnerabilidades (Safety)
      run: safety check

    - name: üõ°Ô∏è An√°lise de seguran√ßa (Bandit)
      run: bandit -r . -f json -o bandit-report.json

    - name: üß™ Executar testes
      run: |
        pytest --cov=. --cov-report=xml --cov-report=html
      env:
        REDIS_HOST: localhost
        REDIS_PORT: 6379

    - name: üìä Upload cobertura para Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  # ========================================
  # JOB 2: BUILD E PUSH DA IMAGEM DOCKER
  # ========================================
  build:
    needs: test
    runs-on: ubuntu-latest
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - name: üì• Checkout do c√≥digo
      uses: actions/checkout@v3

    - name: üîê Login no Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: üìù Extrair metadados
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=sha,prefix={{branch}}-

    - name: üèóÔ∏è Build e Push da imagem
      id: build
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

  # ========================================
  # JOB 3: DEPLOY EM STAGING
  # ========================================
  deploy-staging:
    if: github.ref == 'refs/heads/develop'
    needs: build
    runs-on: ubuntu-latest
    environment: staging
    
    steps:
    - name: üöÄ Deploy para Staging
      run: |
        echo "Deploying to staging environment..."
        # Aqui voc√™ adicionaria comandos espec√≠ficos do seu provedor
        # Exemplos: kubectl, terraform, ansible, etc.

  # ========================================
  # JOB 4: DEPLOY EM PRODU√á√ÉO
  # ========================================
  deploy-production:
    if: github.ref == 'refs/heads/main'
    needs: build
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: üéØ Deploy para Produ√ß√£o
      run: |
        echo "Deploying to production environment..."
        # Deploy em produ√ß√£o com aprova√ß√£o manual

# ========================================
# TESTES AUTOMATIZADOS
# ========================================

# tests/test_app.py
import pytest
import json
from app import app

@pytest.fixture
def client():
    """Cliente de teste para Flask"""
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_health_check(client):
    """Teste do endpoint de sa√∫de"""
    response = client.get('/health')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert data['status'] == 'healthy'

def test_get_users(client):
    """Teste da API de usu√°rios"""
    response = client.get('/api/users')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert len(data) > 0
    assert 'name' in data[0]
    assert 'email' in data[0]

def test_metrics_endpoint(client):
    """Teste do endpoint de m√©tricas"""
    response = client.get('/api/metrics')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert 'cpu_percent' in data
    assert 'memory_percent' in data

# ========================================
# CONFIGURA√á√ÉO PYTEST
# ========================================

# pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --cov-report=term-missing
    --cov-fail-under=80

# ========================================
# CONFIGURA√á√ÉO DE QUALIDADE DE C√ìDIGO
# ========================================

# .flake8
[flake8]
max-line-length = 88
exclude = .git,__pycache__,venv
ignore = E203,W503

# pyproject.toml
[tool.black]
line-length = 88
target-version = ['py311']

[tool.isort]
profile = "black"
multi_line_output = 3

print("‚öôÔ∏è CI/CD EM A√á√ÉO:")
print("1. Testes autom√°ticos a cada push")
print("2. Verifica√ß√£o de qualidade de c√≥digo")
print("3. An√°lise de seguran√ßa")
print("4. Build autom√°tico da imagem Docker")
print("5. Deploy autom√°tico por ambiente")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _cloud_deployment(self):
        """Cloud e Deploy - Parte 3"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("‚òÅÔ∏è CLOUD E DEPLOY EM PRODU√á√ÉO")
        
        print("üå©Ô∏è Deploy em cloud √© essencial para aplica√ß√µes modernas!")
        print("üéØ Estrat√©gias de deploy:")
        print("‚Ä¢ üöÄ Kubernetes para orquestra√ß√£o")
        print("‚Ä¢ üìà Auto-scaling baseado em demanda")
        print("‚Ä¢ üîÑ Load balancing inteligente")
        print("‚Ä¢ üìä Monitoramento e observabilidade")
        print("‚Ä¢ üîí Seguran√ßa e compliance")
        
        codigo = '''# ========================================
# KUBERNETES DEPLOYMENT
# ========================================

# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: minha-app
  labels:
    name: minha-app

---
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  namespace: minha-app
  labels:
    app: webapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: ghcr.io/usuario/minha-app:latest
        ports:
        - containerPort: 5000
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: REDIS_PORT
          value: "6379"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
  namespace: minha-app
spec:
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: ClusterIP

---
# k8s/redis.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-deployment
  namespace: minha-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi

---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: minha-app
spec:
  selector:
    app: redis
  ports:
  - protocol: TCP
    port: 6379
    targetPort: 6379

---
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webapp-ingress
  namespace: minha-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - minha-app.exemplo.com
    secretName: webapp-tls
  rules:
  - host: minha-app.exemplo.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: webapp-service
            port:
              number: 80

# ========================================
# HORIZONTAL POD AUTOSCALER
# ========================================

# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
  namespace: minha-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

# ========================================
# TERRAFORM PARA INFRAESTRUTURA COMO C√ìDIGO
# ========================================

# terraform/main.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# VPC e Networking
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "minha-app-vpc"
  }
}

resource "aws_subnet" "public" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 1}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  map_public_ip_on_launch = true

  tags = {
    Name = "Public Subnet ${count.index + 1}"
  }
}

# EKS Cluster
resource "aws_eks_cluster" "main" {
  name     = "minha-app-cluster"
  role_arn = aws_iam_role.cluster.arn

  vpc_config {
    subnet_ids = aws_subnet.public[*].id
  }

  depends_on = [
    aws_iam_role_policy_attachment.cluster_policy,
  ]
}

# EKS Node Group
resource "aws_eks_node_group" "main" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "main-nodes"
  node_role_arn   = aws_iam_role.node.arn
  subnet_ids      = aws_subnet.public[*].id

  scaling_config {
    desired_size = 2
    max_size     = 4
    min_size     = 1
  }

  instance_types = ["t3.medium"]

  depends_on = [
    aws_iam_role_policy_attachment.node_policy,
    aws_iam_role_policy_attachment.cni_policy,
    aws_iam_role_policy_attachment.registry_policy,
  ]
}

# ========================================
# MONITORAMENTO COM PROMETHEUS E GRAFANA
# ========================================

# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    
    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

    - job_name: 'minha-app'
      static_configs:
      - targets: ['webapp-service.minha-app.svc.cluster.local:80']
        labels:
          service: 'webapp'

---
# monitoring/grafana-dashboard.json
{
  "dashboard": {
    "title": "Minha App Dashboard",
    "panels": [
      {
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total[5m])",
            "legendFormat": "{{pod}}"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph", 
        "targets": [
          {
            "expr": "container_memory_usage_bytes",
            "legendFormat": "{{pod}}"
          }
        ]
      },
      {
        "title": "HTTP Requests",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      }
    ]
  }
}

# ========================================
# SCRIPTS DE DEPLOY
# ========================================

#!/bin/bash
# scripts/deploy.sh

set -e

echo "üöÄ Iniciando deploy da aplica√ß√£o..."

# Vari√°veis
NAMESPACE="minha-app"
IMAGE_TAG=${1:-latest}
CLUSTER_NAME="minha-app-cluster"

# Verificar se kubectl est√° configurado
if ! kubectl cluster-info &> /dev/null; then
    echo "‚ùå kubectl n√£o est√° configurado"
    exit 1
fi

# Criar namespace se n√£o existir
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# Aplicar configura√ß√µes do Kubernetes
echo "üìù Aplicando configura√ß√µes do Kubernetes..."
kubectl apply -f k8s/ -n $NAMESPACE

# Atualizar imagem do deployment
echo "üîÑ Atualizando imagem para $IMAGE_TAG..."
kubectl set image deployment/webapp-deployment webapp=ghcr.io/usuario/minha-app:$IMAGE_TAG -n $NAMESPACE

# Aguardar rollout
echo "‚è≥ Aguardando rollout..."
kubectl rollout status deployment/webapp-deployment -n $NAMESPACE

# Verificar sa√∫de da aplica√ß√£o
echo "üè• Verificando sa√∫de da aplica√ß√£o..."
EXTERNAL_IP=$(kubectl get service webapp-service -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

if [ ! -z "$EXTERNAL_IP" ]; then
    curl -f http://$EXTERNAL_IP/health || {
        echo "‚ùå Aplica√ß√£o n√£o est√° respondendo"
        exit 1
    }
    echo "‚úÖ Deploy conclu√≠do com sucesso!"
    echo "üåê Aplica√ß√£o dispon√≠vel em: http://$EXTERNAL_IP"
else
    echo "‚ö†Ô∏è IP externo ainda n√£o dispon√≠vel"
fi

print("‚òÅÔ∏è CLOUD EM A√á√ÉO:")
print("1. Kubernetes para orquestra√ß√£o")
print("2. Auto-scaling baseado em CPU/Mem√≥ria")
print("3. Load balancing autom√°tico")
print("4. Monitoramento com Prometheus/Grafana")
print("5. Infraestrutura como c√≥digo com Terraform")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _mini_projeto_devops_pipeline(self):
        """Mini Projeto - Pipeline DevOps Completo"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("üéØ MINI-PROJETO: PIPELINE DEVOPS COMPLETO")
        else:
            print("\n" + "="*50)
            print("üéØ MINI-PROJETO: PIPELINE DEVOPS COMPLETO")
            print("="*50)
        
        print("üöÄ DESAFIO √âPICO: Criar um pipeline DevOps do zero ao deploy!")
        print("üèÜ Este projeto integra TODOS os conceitos de DevOps moderno!")
        
        self.pausar()
        
        print("\nüéØ OBJETIVOS DO PROJETO:")
        print("‚úÖ Aplica√ß√£o web com API REST")
        print("‚úÖ Containeriza√ß√£o com Docker")
        print("‚úÖ Pipeline CI/CD com GitHub Actions")
        print("‚úÖ Testes automatizados")
        print("‚úÖ Deploy em Kubernetes")
        print("‚úÖ Monitoramento e m√©tricas")
        print("‚úÖ Seguran√ßa e compliance")
        
        codigo_projeto = '''# ========================================
# PROJETO DEVOPS COMPLETO
# E-COMMERCE MICROSERVICES COM FULL DEVOPS
# ========================================

# Estrutura do projeto:
"""
ecommerce-devops/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ user-service/          # Microservi√ßo de usu√°rios
‚îÇ   ‚îú‚îÄ‚îÄ product-service/       # Microservi√ßo de produtos
‚îÇ   ‚îú‚îÄ‚îÄ order-service/         # Microservi√ßo de pedidos
‚îÇ   ‚îî‚îÄ‚îÄ api-gateway/           # Gateway principal
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/             # Infraestrutura como c√≥digo
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/            # Manifestos K8s
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/            # Prometheus/Grafana
‚îú‚îÄ‚îÄ .github/workflows/         # CI/CD pipelines
‚îú‚îÄ‚îÄ docker-compose.yml         # Desenvolvimento local
‚îî‚îÄ‚îÄ README.md
"""

# ========================================
# 1. MICROSERVI√áO DE USU√ÅRIOS
# ========================================

# services/user-service/app.py
from flask import Flask, jsonify, request
from flask_sqlalchemy import SQLAlchemy
from werkzeug.security import generate_password_hash, check_password_hash
import jwt
import os
from datetime import datetime, timedelta
import logging

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
    'DATABASE_URL', 'postgresql://user:pass@localhost/users'
)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret')

db = SQLAlchemy(app)
logging.basicConfig(level=logging.INFO)

class User(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(120), unique=True, nullable=False)
    password_hash = db.Column(db.String(128))
    name = db.Column(db.String(100), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    active = db.Column(db.Boolean, default=True)

@app.route('/health')
def health():
    return jsonify({'status': 'healthy', 'service': 'user-service'})

@app.route('/api/users/register', methods=['POST'])
def register():
    data = request.get_json()
    
    if User.query.filter_by(email=data['email']).first():
        return jsonify({'error': 'Email j√° cadastrado'}), 400
    
    user = User(
        email=data['email'],
        name=data['name'],
        password_hash=generate_password_hash(data['password'])
    )
    
    db.session.add(user)
    db.session.commit()
    
    return jsonify({'message': 'Usu√°rio criado com sucesso'}), 201

@app.route('/api/users/login', methods=['POST'])
def login():
    data = request.get_json()
    user = User.query.filter_by(email=data['email']).first()
    
    if user and check_password_hash(user.password_hash, data['password']):
        token = jwt.encode({
            'user_id': user.id,
            'exp': datetime.utcnow() + timedelta(hours=24)
        }, app.config['SECRET_KEY'])
        
        return jsonify({'token': token})
    
    return jsonify({'error': 'Credenciais inv√°lidas'}), 401

# services/user-service/Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5001

CMD ["gunicorn", "--bind", "0.0.0.0:5001", "app:app"]

# ========================================
# 2. MICROSERVI√áO DE PRODUTOS
# ========================================

# services/product-service/app.py
from flask import Flask, jsonify, request
from flask_sqlalchemy import SQLAlchemy
import os
import logging
from datetime import datetime

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
    'DATABASE_URL', 'postgresql://user:pass@localhost/products'
)

db = SQLAlchemy(app)
logging.basicConfig(level=logging.INFO)

class Product(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(200), nullable=False)
    description = db.Column(db.Text)
    price = db.Column(db.Numeric(10, 2), nullable=False)
    stock = db.Column(db.Integer, default=0)
    category = db.Column(db.String(100))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    active = db.Column(db.Boolean, default=True)

@app.route('/health')
def health():
    return jsonify({'status': 'healthy', 'service': 'product-service'})

@app.route('/api/products', methods=['GET'])
def get_products():
    products = Product.query.filter_by(active=True).all()
    return jsonify([{
        'id': p.id,
        'name': p.name,
        'description': p.description,
        'price': float(p.price),
        'stock': p.stock,
        'category': p.category
    } for p in products])

@app.route('/api/products', methods=['POST'])
def create_product():
    data = request.get_json()
    
    product = Product(
        name=data['name'],
        description=data.get('description', ''),
        price=data['price'],
        stock=data.get('stock', 0),
        category=data.get('category', 'general')
    )
    
    db.session.add(product)
    db.session.commit()
    
    return jsonify({'message': 'Produto criado com sucesso'}), 201

# ========================================
# 3. API GATEWAY
# ========================================

# services/api-gateway/app.py
from flask import Flask, request, jsonify
import requests
import os
import logging

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# URLs dos microservi√ßos
USER_SERVICE_URL = os.getenv('USER_SERVICE_URL', 'http://user-service:5001')
PRODUCT_SERVICE_URL = os.getenv('PRODUCT_SERVICE_URL', 'http://product-service:5002')
ORDER_SERVICE_URL = os.getenv('ORDER_SERVICE_URL', 'http://order-service:5003')

@app.route('/health')
def health():
    # Verificar sa√∫de de todos os servi√ßos
    services_health = {}
    
    try:
        resp = requests.get(f'{USER_SERVICE_URL}/health', timeout=5)
        services_health['user-service'] = resp.json()
    except:
        services_health['user-service'] = {'status': 'unhealthy'}
    
    try:
        resp = requests.get(f'{PRODUCT_SERVICE_URL}/health', timeout=5)
        services_health['product-service'] = resp.json()
    except:
        services_health['product-service'] = {'status': 'unhealthy'}
    
    return jsonify({
        'status': 'healthy',
        'service': 'api-gateway',
        'services': services_health
    })

@app.route('/api/users/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_users(path):
    url = f'{USER_SERVICE_URL}/api/users/{path}'
    return proxy_request(url)

@app.route('/api/products/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_products(path):
    url = f'{PRODUCT_SERVICE_URL}/api/products/{path}'
    return proxy_request(url)

def proxy_request(url):
    try:
        resp = requests.request(
            method=request.method,
            url=url,
            headers=dict(request.headers),
            data=request.get_data(),
            cookies=request.cookies,
            allow_redirects=False,
            timeout=30
        )
        
        return resp.content, resp.status_code, resp.headers.items()
    
    except requests.exceptions.Timeout:
        return jsonify({'error': 'Service timeout'}), 504
    except requests.exceptions.ConnectionError:
        return jsonify({'error': 'Service unavailable'}), 503

# ========================================
# 4. PIPELINE CI/CD AVAN√áADO
# ========================================

# .github/workflows/microservices-ci-cd.yml
name: Microservices CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository }}/

jobs:
  # ========================================
  # DETECTAR MUDAN√áAS EM SERVI√áOS
  # ========================================
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      user-service: ${{ steps.changes.outputs.user-service }}
      product-service: ${{ steps.changes.outputs.product-service }}
      api-gateway: ${{ steps.changes.outputs.api-gateway }}
    steps:
    - uses: actions/checkout@v3
    - uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          user-service:
            - 'services/user-service/**'
          product-service:
            - 'services/product-service/**'
          api-gateway:
            - 'services/api-gateway/**'

  # ========================================
  # TESTES E BUILD PARALELO POR SERVI√áO
  # ========================================
  build-user-service:
    needs: detect-changes
    if: needs.detect-changes.outputs.user-service == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: üß™ Testes do User Service
      run: |
        cd services/user-service
        pip install -r requirements.txt
        pytest tests/ --cov=. --cov-report=xml
    
    - name: üê≥ Build e Push User Service
      uses: docker/build-push-action@v4
      with:
        context: services/user-service
        push: true
        tags: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}

  build-product-service:
    needs: detect-changes
    if: needs.detect-changes.outputs.product-service == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: üß™ Testes do Product Service
      run: |
        cd services/product-service
        pip install -r requirements.txt
        pytest tests/ --cov=. --cov-report=xml
    
    - name: üê≥ Build e Push Product Service
      uses: docker/build-push-action@v4
      with:
        context: services/product-service
        push: true
        tags: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}product-service:${{ github.sha }}

  # ========================================
  # TESTES DE INTEGRA√á√ÉO
  # ========================================
  integration-tests:
    needs: [build-user-service, build-product-service]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: üöÄ Subir ambiente de teste
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30  # Aguardar servi√ßos subirem
    
    - name: üß™ Executar testes de integra√ß√£o
      run: |
        pytest tests/integration/ --verbose
    
    - name: üìä Testes de carga com K6
      run: |
        docker run --rm -i grafana/k6 run - <tests/load/api-test.js

  # ========================================
  # AN√ÅLISE DE SEGURAN√áA
  # ========================================
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: üîí Scan de vulnerabilidades
      uses: anchore/scan-action@v3
      with:
        image: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}
    
    - name: üõ°Ô∏è An√°lise de c√≥digo com CodeQL
      uses: github/codeql-action/analyze@v2

  # ========================================
  # DEPLOY STAGING
  # ========================================
  deploy-staging:
    if: github.ref == 'refs/heads/develop'
    needs: [integration-tests, security-scan]
    runs-on: ubuntu-latest
    environment: staging
    steps:
    - name: üöÄ Deploy para Staging
      run: |
        echo "Deploying to staging with GitOps..."
        # Atualizar manifesto no reposit√≥rio GitOps
        
  # ========================================
  # DEPLOY PRODU√á√ÉO COM CANARY
  # ========================================
  deploy-production:
    if: github.ref == 'refs/heads/main'
    needs: [integration-tests, security-scan]
    runs-on: ubuntu-latest
    environment: production
    steps:
    - name: üéØ Canary Deploy
      run: |
        # Deploy can√°rio com 10% do tr√°fego
        kubectl patch deployment user-service \\
          -p '{"spec":{"template":{"spec":{"containers":[{"name":"user-service","image":"'${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}'"}]}}}}'
        
        # Aguardar m√©tricas
        sleep 300
        
        # Se m√©tricas OK, deploy completo
        kubectl scale deployment user-service-canary --replicas=0

# ========================================
# 5. MONITORAMENTO AVAN√áADO
# ========================================

# monitoring/prometheus-rules.yml
groups:
- name: ecommerce.rules
  rules:
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service {{ $labels.job }} is down"
      
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate on {{ $labels.service }}"
      
  - alert: HighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High latency on {{ $labels.service }}"

print("üéØ PROJETO DEVOPS √âPICO:")
print("üèóÔ∏è 1. Arquitetura de microservi√ßos")
print("üê≥ 2. Containeriza√ß√£o completa")
print("‚öôÔ∏è 3. CI/CD com deploy can√°rio")
print("üß™ 4. Testes automatizados (unit + integration + load)")
print("üîí 5. An√°lise de seguran√ßa autom√°tica")
print("‚òÅÔ∏è 6. Kubernetes com auto-scaling")
print("üìä 7. Monitoramento full-stack")
print("üö® 8. Alertas inteligentes")
print("üìà 9. M√©tricas de neg√≥cio")
print("üîÑ 10. GitOps para deploy")
print("")
print("üèÜ ESTE √â O N√çVEL DE UM SENIOR DEVOPS ENGINEER!")
'''
        
        self.exemplo(codigo_projeto)
        
        print("\nüéä CARACTER√çSTICAS DO PROJETO:")
        print("‚úÖ Microservi√ßos em Python/Flask")
        print("‚úÖ API Gateway para roteamento")
        print("‚úÖ Banco PostgreSQL por servi√ßo")
        print("‚úÖ Redis para cache distribu√≠do")
        print("‚úÖ Docker Compose para desenvolvimento")
        print("‚úÖ Kubernetes para produ√ß√£o")
        print("‚úÖ Pipeline CI/CD com GitHub Actions")
        print("‚úÖ Testes automatizados em 3 n√≠veis")
        print("‚úÖ Deploy can√°rio para zero downtime")
        print("‚úÖ Monitoramento com Prometheus/Grafana")
        print("‚úÖ Alertas inteligentes")
        print("‚úÖ Logs centralizados")
        print("‚úÖ M√©tricas de neg√≥cio")
        
        print("\nüöÄ TECNOLOGIAS ENTERPRISE:")
        print("‚Ä¢ üê≥ Docker & Docker Compose")
        print("‚Ä¢ ‚ò∏Ô∏è Kubernetes")
        print("‚Ä¢ ‚öôÔ∏è GitHub Actions")
        print("‚Ä¢ üèóÔ∏è Terraform")
        print("‚Ä¢ üìä Prometheus & Grafana")
        print("‚Ä¢ üîç Jaeger (tracing)")
        print("‚Ä¢ üìù ELK Stack (logs)")
        print("‚Ä¢ üîí OWASP ZAP (security)")
        print("‚Ä¢ üß™ Jest & K6 (testing)")
        print("‚Ä¢ üåê Nginx (load balancer)")
        
        # Registra conclus√£o do projeto
        self.complete_mini_project("Pipeline DevOps Completo - E-commerce Microservices")
        
        print("\nüèÜ PARAB√âNS! Voc√™ dominou DevOps de n√≠vel SENIOR!")
        print("üéØ Este projeto demonstra capacidade t√©cnica para:")
        print("‚Ä¢ üíº Senior DevOps Engineer")
        print("‚Ä¢ üèóÔ∏è Platform Engineer")
        print("‚Ä¢ ‚òÅÔ∏è Cloud Architect")
        print("‚Ä¢ üîß Site Reliability Engineer (SRE)")
        
        self.pausar()
