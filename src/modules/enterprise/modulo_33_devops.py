#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MÃ³dulo 33: DevOps Completo - Docker, CI/CD e Cloud
Aprenda DevOps profissional: containerizaÃ§Ã£o, integraÃ§Ã£o contÃ­nua e deploy em cloud
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any, Protocol, Union
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import uuid
from ..shared.base_module import BaseModule


class Modulo33DevOps(BaseModule):
    """MÃ³dulo 33: DevOps Completo - Docker, CI/CD e Cloud"""
    
    def __init__(self):
        super().__init__("modulo_33", "DevOps Completo - Docker, CI/CD e Cloud")
        self.has_mini_project = True
        self.mini_project_points = 150
    
    def execute(self) -> None:
        """Executa o mÃ³dulo sobre DevOps"""
        if not self.ui or not self.progress:
            print("âŒ Erro: DependÃªncias nÃ£o configuradas para este mÃ³dulo")
            self.pausar()
            return
        
        try:
            self._devops_intro()
        except Exception as e:
            self.error_handler(lambda: None)
    
    def _devops_intro(self) -> None:
        """ConteÃºdo principal sobre DevOps"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("ğŸš€ MÃ“DULO 33: DEVOPS COMPLETO - DOCKER, CI/CD E CLOUD")
        else:
            print("\n" + "="*60)
            print("ğŸš€ MÃ“DULO 33: DEVOPS COMPLETO - DOCKER, CI/CD E CLOUD")
            print("="*60)
        
        print("ğŸ¯ DevOps Ã© fundamental para desenvolvimento moderno!")
        print("ğŸ› ï¸ Domine as ferramentas que empresas reais usam:")
        print("â€¢ ğŸ³ Docker para containerizaÃ§Ã£o")
        print("â€¢ âš™ï¸ CI/CD para automaÃ§Ã£o")
        print("â€¢ â˜ï¸ Cloud para deploy e escala")
        print("â€¢ ğŸ“Š Monitoramento e observabilidade")
        print("â€¢ ğŸ”’ SeguranÃ§a e compliance")
        print("â€¢ ğŸš€ DevSecOps e GitOps")
        
        self.pausar()
        
        self._docker_containerization()
        self._ci_cd_pipeline()
        self._cloud_deployment()
        self._mini_projeto_devops_pipeline()
        
        # Marcar mÃ³dulo como completo
        self.complete_module()
    
    def _docker_containerization(self):
        """Docker e ContainerizaÃ§Ã£o - Parte 1"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("ğŸ³ DOCKER E CONTAINERIZAÃ‡ÃƒO")
        
        print("ğŸ“¦ Docker revolucionou o desenvolvimento de software!")
        print("ğŸ¯ BenefÃ­cios da containerizaÃ§Ã£o:")
        print("â€¢ âš¡ Portabilidade entre ambientes")
        print("â€¢ ğŸ”’ Isolamento de aplicaÃ§Ãµes")
        print("â€¢ ğŸ“ˆ Escalabilidade horizontal")
        print("â€¢ ğŸš€ Deploy rÃ¡pido e consistente")
        print("â€¢ ğŸ’° OtimizaÃ§Ã£o de recursos")
        
        codigo = '''# ========================================
# DOCKER FUNDAMENTALS
# ========================================

# 1. DOCKERFILE - Receita para criar imagem
# Dockerfile para aplicaÃ§Ã£o Python Flask

FROM python:3.11-slim

# Metadados da imagem
LABEL maintainer="dev@empresa.com"
LABEL version="1.0"
LABEL description="API Python com Flask"

# Definir diretÃ³rio de trabalho
WORKDIR /app

# Instalar dependÃªncias do sistema
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copiar arquivos de dependÃªncias
COPY requirements.txt .

# Instalar dependÃªncias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copiar cÃ³digo da aplicaÃ§Ã£o
COPY . .

# Criar usuÃ¡rio nÃ£o-root (seguranÃ§a)
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expor porta da aplicaÃ§Ã£o
EXPOSE 5000

# Comando para executar a aplicaÃ§Ã£o
CMD ["python", "app.py"]

# ========================================
# APLICAÃ‡ÃƒO FLASK EXEMPLO
# ========================================

# app.py
from flask import Flask, jsonify, request
import os
import redis
import json
from datetime import datetime
import logging

app = Flask(__name__)

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Conectar ao Redis (se disponÃ­vel)
try:
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        decode_responses=True
    )
    redis_client.ping()
    logger.info("âœ… Conectado ao Redis")
except:
    redis_client = None
    logger.warning("âš ï¸ Redis nÃ£o disponÃ­vel")

@app.route('/health')
def health_check():
    """Endpoint para verificaÃ§Ã£o de saÃºde"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'redis': 'connected' if redis_client else 'disconnected'
    })

@app.route('/api/users', methods=['GET'])
def get_users():
    """API para listar usuÃ¡rios"""
    if redis_client:
        # Tentar buscar do cache
        cached_users = redis_client.get('users')
        if cached_users:
            return jsonify(json.loads(cached_users))
    
    # Dados mock para exemplo
    users = [
        {'id': 1, 'name': 'JoÃ£o Silva', 'email': 'joao@email.com'},
        {'id': 2, 'name': 'Maria Santos', 'email': 'maria@email.com'},
        {'id': 3, 'name': 'Pedro Lima', 'email': 'pedro@email.com'}
    ]
    
    # Salvar no cache (se disponÃ­vel)
    if redis_client:
        redis_client.setex('users', 300, json.dumps(users))
    
    return jsonify(users)

@app.route('/api/metrics')
def get_metrics():
    """Endpoint para mÃ©tricas da aplicaÃ§Ã£o"""
    import psutil
    
    return jsonify({
        'cpu_percent': psutil.cpu_percent(),
        'memory_percent': psutil.virtual_memory().percent,
        'disk_usage': psutil.disk_usage('/').percent,
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)

# ========================================
# REQUIREMENTS.TXT
# ========================================
"""
Flask==2.3.2
redis==4.6.0
psutil==5.9.5
gunicorn==21.2.0
"""

# ========================================
# DOCKER COMPOSE - ORQUESTRAÃ‡ÃƒO DE CONTAINERS
# ========================================

# docker-compose.yml
version: '3.8'

services:
  # ServiÃ§o da aplicaÃ§Ã£o Python
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PORT=5000
    depends_on:
      - redis
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
    networks:
      - app-network

  # ServiÃ§o Redis para cache
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - app-network

  # Nginx como proxy reverso
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - web
    restart: unless-stopped
    networks:
      - app-network

  # Monitoramento com Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - app-network

volumes:
  redis_data:

networks:
  app-network:
    driver: bridge

# ========================================
# COMANDOS DOCKER ESSENCIAIS
# ========================================

# Construir imagem
docker build -t minha-app:1.0 .

# Executar container
docker run -d -p 5000:5000 --name minha-app minha-app:1.0

# Ver containers rodando
docker ps

# Ver logs do container
docker logs minha-app

# Executar comando dentro do container
docker exec -it minha-app bash

# Parar container
docker stop minha-app

# Remover container
docker rm minha-app

# Usar Docker Compose
docker-compose up -d
docker-compose logs -f
docker-compose down

# ========================================
# CONFIGURAÃ‡ÃƒO NGINX
# ========================================

# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream webapp {
        server web:5000;
    }

    server {
        listen 80;
        
        location / {
            proxy_pass http://webapp;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        
        location /health {
            proxy_pass http://webapp/health;
        }
    }
}

print("ğŸ³ DOCKER EM AÃ‡ÃƒO:")
print("1. Dockerfile define a imagem")
print("2. Docker Compose orquestra mÃºltiplos containers")
print("3. Nginx como proxy reverso")
print("4. Redis para cache e sessÃµes")
print("5. Prometheus para monitoramento")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _ci_cd_pipeline(self):
        """CI/CD Pipeline - Parte 2"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("âš™ï¸ CI/CD - INTEGRAÃ‡ÃƒO E ENTREGA CONTÃNUA")
        
        print("ğŸ”„ CI/CD automatiza todo o ciclo de desenvolvimento!")
        print("ğŸ¯ BenefÃ­cios da automaÃ§Ã£o:")
        print("â€¢ âœ¨ Testes automÃ¡ticos a cada commit")
        print("â€¢ ğŸš€ Deploy automÃ¡tico em produÃ§Ã£o")
        print("â€¢ ğŸ”’ VerificaÃ§Ãµes de seguranÃ§a")
        print("â€¢ ğŸ“Š Qualidade de cÃ³digo garantida")
        print("â€¢ âš¡ Feedback rÃ¡pido para desenvolvedores")
        
        codigo = '''# ========================================
# GITHUB ACTIONS - CI/CD PIPELINE
# ========================================

# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ========================================
  # JOB 1: TESTES E QUALIDADE DE CÃ“DIGO
  # ========================================
  test:
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: ğŸ“¥ Checkout do cÃ³digo
      uses: actions/checkout@v3

    - name: ğŸ Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: ğŸ“¦ Instalar dependÃªncias
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black isort safety bandit

    - name: ğŸ§¹ Verificar formataÃ§Ã£o (Black)
      run: black --check .

    - name: ğŸ“ Verificar importaÃ§Ãµes (isort)
      run: isort --check-only .

    - name: ğŸ” AnÃ¡lise estÃ¡tica (Flake8)
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

    - name: ğŸ”’ Verificar vulnerabilidades (Safety)
      run: safety check

    - name: ğŸ›¡ï¸ AnÃ¡lise de seguranÃ§a (Bandit)
      run: bandit -r . -f json -o bandit-report.json

    - name: ğŸ§ª Executar testes
      run: |
        pytest --cov=. --cov-report=xml --cov-report=html
      env:
        REDIS_HOST: localhost
        REDIS_PORT: 6379

    - name: ğŸ“Š Upload cobertura para Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  # ========================================
  # JOB 2: BUILD E PUSH DA IMAGEM DOCKER
  # ========================================
  build:
    needs: test
    runs-on: ubuntu-latest
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - name: ğŸ“¥ Checkout do cÃ³digo
      uses: actions/checkout@v3

    - name: ğŸ” Login no Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: ğŸ“ Extrair metadados
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=sha,prefix={{branch}}-

    - name: ğŸ—ï¸ Build e Push da imagem
      id: build
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

  # ========================================
  # JOB 3: DEPLOY EM STAGING
  # ========================================
  deploy-staging:
    if: github.ref == 'refs/heads/develop'
    needs: build
    runs-on: ubuntu-latest
    environment: staging
    
    steps:
    - name: ğŸš€ Deploy para Staging
      run: |
        echo "Deploying to staging environment..."
        # Aqui vocÃª adicionaria comandos especÃ­ficos do seu provedor
        # Exemplos: kubectl, terraform, ansible, etc.

  # ========================================
  # JOB 4: DEPLOY EM PRODUÃ‡ÃƒO
  # ========================================
  deploy-production:
    if: github.ref == 'refs/heads/main'
    needs: build
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: ğŸ¯ Deploy para ProduÃ§Ã£o
      run: |
        echo "Deploying to production environment..."
        # Deploy em produÃ§Ã£o com aprovaÃ§Ã£o manual

# ========================================
# TESTES AUTOMATIZADOS
# ========================================

# tests/test_app.py
import pytest
import json
from app import app

@pytest.fixture
def client():
    """Cliente de teste para Flask"""
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_health_check(client):
    """Teste do endpoint de saÃºde"""
    response = client.get('/health')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert data['status'] == 'healthy'

def test_get_users(client):
    """Teste da API de usuÃ¡rios"""
    response = client.get('/api/users')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert len(data) > 0
    assert 'name' in data[0]
    assert 'email' in data[0]

def test_metrics_endpoint(client):
    """Teste do endpoint de mÃ©tricas"""
    response = client.get('/api/metrics')
    assert response.status_code == 200
    data = json.loads(response.data)
    assert 'cpu_percent' in data
    assert 'memory_percent' in data

# ========================================
# CONFIGURAÃ‡ÃƒO PYTEST
# ========================================

# pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --cov-report=term-missing
    --cov-fail-under=80

# ========================================
# CONFIGURAÃ‡ÃƒO DE QUALIDADE DE CÃ“DIGO
# ========================================

# .flake8
[flake8]
max-line-length = 88
exclude = .git,__pycache__,venv
ignore = E203,W503

# pyproject.toml
[tool.black]
line-length = 88
target-version = ['py311']

[tool.isort]
profile = "black"
multi_line_output = 3

print("âš™ï¸ CI/CD EM AÃ‡ÃƒO:")
print("1. Testes automÃ¡ticos a cada push")
print("2. VerificaÃ§Ã£o de qualidade de cÃ³digo")
print("3. AnÃ¡lise de seguranÃ§a")
print("4. Build automÃ¡tico da imagem Docker")
print("5. Deploy automÃ¡tico por ambiente")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _cloud_deployment(self):
        """Cloud e Deploy - Parte 3"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("â˜ï¸ CLOUD E DEPLOY EM PRODUÃ‡ÃƒO")
        
        print("ğŸŒ©ï¸ Deploy em cloud Ã© essencial para aplicaÃ§Ãµes modernas!")
        print("ğŸ¯ EstratÃ©gias de deploy:")
        print("â€¢ ğŸš€ Kubernetes para orquestraÃ§Ã£o")
        print("â€¢ ğŸ“ˆ Auto-scaling baseado em demanda")
        print("â€¢ ğŸ”„ Load balancing inteligente")
        print("â€¢ ğŸ“Š Monitoramento e observabilidade")
        print("â€¢ ğŸ”’ SeguranÃ§a e compliance")
        
        codigo = '''# ========================================
# KUBERNETES DEPLOYMENT
# ========================================

# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: minha-app
  labels:
    name: minha-app

---
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webapp-deployment
  namespace: minha-app
  labels:
    app: webapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        image: ghcr.io/usuario/minha-app:latest
        ports:
        - containerPort: 5000
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: REDIS_PORT
          value: "6379"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: webapp-service
  namespace: minha-app
spec:
  selector:
    app: webapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: ClusterIP

---
# k8s/redis.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-deployment
  namespace: minha-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi

---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: minha-app
spec:
  selector:
    app: redis
  ports:
  - protocol: TCP
    port: 6379
    targetPort: 6379

---
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webapp-ingress
  namespace: minha-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - minha-app.exemplo.com
    secretName: webapp-tls
  rules:
  - host: minha-app.exemplo.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: webapp-service
            port:
              number: 80

# ========================================
# HORIZONTAL POD AUTOSCALER
# ========================================

# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
  namespace: minha-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

# ========================================
# TERRAFORM PARA INFRAESTRUTURA COMO CÃ“DIGO
# ========================================

# terraform/main.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# VPC e Networking
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "minha-app-vpc"
  }
}

resource "aws_subnet" "public" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 1}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  map_public_ip_on_launch = true

  tags = {
    Name = "Public Subnet ${count.index + 1}"
  }
}

# EKS Cluster
resource "aws_eks_cluster" "main" {
  name     = "minha-app-cluster"
  role_arn = aws_iam_role.cluster.arn

  vpc_config {
    subnet_ids = aws_subnet.public[*].id
  }

  depends_on = [
    aws_iam_role_policy_attachment.cluster_policy,
  ]
}

# EKS Node Group
resource "aws_eks_node_group" "main" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "main-nodes"
  node_role_arn   = aws_iam_role.node.arn
  subnet_ids      = aws_subnet.public[*].id

  scaling_config {
    desired_size = 2
    max_size     = 4
    min_size     = 1
  }

  instance_types = ["t3.medium"]

  depends_on = [
    aws_iam_role_policy_attachment.node_policy,
    aws_iam_role_policy_attachment.cni_policy,
    aws_iam_role_policy_attachment.registry_policy,
  ]
}

# ========================================
# MONITORAMENTO COM PROMETHEUS E GRAFANA
# ========================================

# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    
    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

    - job_name: 'minha-app'
      static_configs:
      - targets: ['webapp-service.minha-app.svc.cluster.local:80']
        labels:
          service: 'webapp'

---
# monitoring/grafana-dashboard.json
{
  "dashboard": {
    "title": "Minha App Dashboard",
    "panels": [
      {
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total[5m])",
            "legendFormat": "{{pod}}"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph", 
        "targets": [
          {
            "expr": "container_memory_usage_bytes",
            "legendFormat": "{{pod}}"
          }
        ]
      },
      {
        "title": "HTTP Requests",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      }
    ]
  }
}

# ========================================
# SCRIPTS DE DEPLOY
# ========================================

#!/bin/bash
# scripts/deploy.sh

set -e

echo "ğŸš€ Iniciando deploy da aplicaÃ§Ã£o..."

# VariÃ¡veis
NAMESPACE="minha-app"
IMAGE_TAG=${1:-latest}
CLUSTER_NAME="minha-app-cluster"

# Verificar se kubectl estÃ¡ configurado
if ! kubectl cluster-info &> /dev/null; then
    echo "âŒ kubectl nÃ£o estÃ¡ configurado"
    exit 1
fi

# Criar namespace se nÃ£o existir
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# Aplicar configuraÃ§Ãµes do Kubernetes
echo "ğŸ“ Aplicando configuraÃ§Ãµes do Kubernetes..."
kubectl apply -f k8s/ -n $NAMESPACE

# Atualizar imagem do deployment
echo "ğŸ”„ Atualizando imagem para $IMAGE_TAG..."
kubectl set image deployment/webapp-deployment webapp=ghcr.io/usuario/minha-app:$IMAGE_TAG -n $NAMESPACE

# Aguardar rollout
echo "â³ Aguardando rollout..."
kubectl rollout status deployment/webapp-deployment -n $NAMESPACE

# Verificar saÃºde da aplicaÃ§Ã£o
echo "ğŸ¥ Verificando saÃºde da aplicaÃ§Ã£o..."
EXTERNAL_IP=$(kubectl get service webapp-service -n $NAMESPACE -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

if [ ! -z "$EXTERNAL_IP" ]; then
    curl -f http://$EXTERNAL_IP/health || {
        echo "âŒ AplicaÃ§Ã£o nÃ£o estÃ¡ respondendo"
        exit 1
    }
    echo "âœ… Deploy concluÃ­do com sucesso!"
    echo "ğŸŒ AplicaÃ§Ã£o disponÃ­vel em: http://$EXTERNAL_IP"
else
    echo "âš ï¸ IP externo ainda nÃ£o disponÃ­vel"
fi

print("â˜ï¸ CLOUD EM AÃ‡ÃƒO:")
print("1. Kubernetes para orquestraÃ§Ã£o")
print("2. Auto-scaling baseado em CPU/MemÃ³ria")
print("3. Load balancing automÃ¡tico")
print("4. Monitoramento com Prometheus/Grafana")
print("5. Infraestrutura como cÃ³digo com Terraform")
'''
        
        self.exemplo(codigo)
        self.pausar()
    
    def _mini_projeto_devops_pipeline(self):
        """Mini Projeto - Pipeline DevOps Completo"""
        if self.ui:
            self.ui.clear_screen()
            self.ui.header("ğŸ¯ MINI-PROJETO: PIPELINE DEVOPS COMPLETO")
        else:
            print("\n" + "="*50)
            print("ğŸ¯ MINI-PROJETO: PIPELINE DEVOPS COMPLETO")
            print("="*50)
        
        print("ğŸš€ DESAFIO Ã‰PICO: Criar um pipeline DevOps do zero ao deploy!")
        print("ğŸ† Este projeto integra TODOS os conceitos de DevOps moderno!")
        
        self.pausar()
        
        print("\nğŸ¯ OBJETIVOS DO PROJETO:")
        print("âœ… AplicaÃ§Ã£o web com API REST")
        print("âœ… ContainerizaÃ§Ã£o com Docker")
        print("âœ… Pipeline CI/CD com GitHub Actions")
        print("âœ… Testes automatizados")
        print("âœ… Deploy em Kubernetes")
        print("âœ… Monitoramento e mÃ©tricas")
        print("âœ… SeguranÃ§a e compliance")
        
        codigo_projeto = '''# ========================================
# PROJETO DEVOPS COMPLETO
# E-COMMERCE MICROSERVICES COM FULL DEVOPS
# ========================================

# Estrutura do projeto:
"""
ecommerce-devops/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ user-service/          # MicroserviÃ§o de usuÃ¡rios
â”‚   â”œâ”€â”€ product-service/       # MicroserviÃ§o de produtos
â”‚   â”œâ”€â”€ order-service/         # MicroserviÃ§o de pedidos
â”‚   â””â”€â”€ api-gateway/           # Gateway principal
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform/             # Infraestrutura como cÃ³digo
â”‚   â”œâ”€â”€ kubernetes/            # Manifestos K8s
â”‚   â””â”€â”€ monitoring/            # Prometheus/Grafana
â”œâ”€â”€ .github/workflows/         # CI/CD pipelines
â”œâ”€â”€ docker-compose.yml         # Desenvolvimento local
â””â”€â”€ README.md
"""

# ========================================
# 1. MICROSERVIÃ‡O DE USUÃRIOS
# ========================================

# services/user-service/app.py
from flask import Flask, jsonify, request
from flask_sqlalchemy import SQLAlchemy
from werkzeug.security import generate_password_hash, check_password_hash
import jwt
import os
from datetime import datetime, timedelta
import logging

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
    'DATABASE_URL', 'postgresql://user:pass@localhost/users'
)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret')

db = SQLAlchemy(app)
logging.basicConfig(level=logging.INFO)

class User(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    email = db.Column(db.String(120), unique=True, nullable=False)
    password_hash = db.Column(db.String(128))
    name = db.Column(db.String(100), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    active = db.Column(db.Boolean, default=True)

@app.route('/health')
def health():
    return jsonify({'status': 'healthy', 'service': 'user-service'})

@app.route('/api/users/register', methods=['POST'])
def register():
    data = request.get_json()
    
    if User.query.filter_by(email=data['email']).first():
        return jsonify({'error': 'Email jÃ¡ cadastrado'}), 400
    
    user = User(
        email=data['email'],
        name=data['name'],
        password_hash=generate_password_hash(data['password'])
    )
    
    db.session.add(user)
    db.session.commit()
    
    return jsonify({'message': 'UsuÃ¡rio criado com sucesso'}), 201

@app.route('/api/users/login', methods=['POST'])
def login():
    data = request.get_json()
    user = User.query.filter_by(email=data['email']).first()
    
    if user and check_password_hash(user.password_hash, data['password']):
        token = jwt.encode({
            'user_id': user.id,
            'exp': datetime.utcnow() + timedelta(hours=24)
        }, app.config['SECRET_KEY'])
        
        return jsonify({'token': token})
    
    return jsonify({'error': 'Credenciais invÃ¡lidas'}), 401

# services/user-service/Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5001

CMD ["gunicorn", "--bind", "0.0.0.0:5001", "app:app"]

# ========================================
# 2. MICROSERVIÃ‡O DE PRODUTOS
# ========================================

# services/product-service/app.py
from flask import Flask, jsonify, request
from flask_sqlalchemy import SQLAlchemy
import os
import logging
from datetime import datetime

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv(
    'DATABASE_URL', 'postgresql://user:pass@localhost/products'
)

db = SQLAlchemy(app)
logging.basicConfig(level=logging.INFO)

class Product(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(200), nullable=False)
    description = db.Column(db.Text)
    price = db.Column(db.Numeric(10, 2), nullable=False)
    stock = db.Column(db.Integer, default=0)
    category = db.Column(db.String(100))
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    active = db.Column(db.Boolean, default=True)

@app.route('/health')
def health():
    return jsonify({'status': 'healthy', 'service': 'product-service'})

@app.route('/api/products', methods=['GET'])
def get_products():
    products = Product.query.filter_by(active=True).all()
    return jsonify([{
        'id': p.id,
        'name': p.name,
        'description': p.description,
        'price': float(p.price),
        'stock': p.stock,
        'category': p.category
    } for p in products])

@app.route('/api/products', methods=['POST'])
def create_product():
    data = request.get_json()
    
    product = Product(
        name=data['name'],
        description=data.get('description', ''),
        price=data['price'],
        stock=data.get('stock', 0),
        category=data.get('category', 'general')
    )
    
    db.session.add(product)
    db.session.commit()
    
    return jsonify({'message': 'Produto criado com sucesso'}), 201

# ========================================
# 3. API GATEWAY
# ========================================

# services/api-gateway/app.py
from flask import Flask, request, jsonify
import requests
import os
import logging

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# URLs dos microserviÃ§os
USER_SERVICE_URL = os.getenv('USER_SERVICE_URL', 'http://user-service:5001')
PRODUCT_SERVICE_URL = os.getenv('PRODUCT_SERVICE_URL', 'http://product-service:5002')
ORDER_SERVICE_URL = os.getenv('ORDER_SERVICE_URL', 'http://order-service:5003')

@app.route('/health')
def health():
    # Verificar saÃºde de todos os serviÃ§os
    services_health = {}
    
    try:
        resp = requests.get(f'{USER_SERVICE_URL}/health', timeout=5)
        services_health['user-service'] = resp.json()
    except:
        services_health['user-service'] = {'status': 'unhealthy'}
    
    try:
        resp = requests.get(f'{PRODUCT_SERVICE_URL}/health', timeout=5)
        services_health['product-service'] = resp.json()
    except:
        services_health['product-service'] = {'status': 'unhealthy'}
    
    return jsonify({
        'status': 'healthy',
        'service': 'api-gateway',
        'services': services_health
    })

@app.route('/api/users/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_users(path):
    url = f'{USER_SERVICE_URL}/api/users/{path}'
    return proxy_request(url)

@app.route('/api/products/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_products(path):
    url = f'{PRODUCT_SERVICE_URL}/api/products/{path}'
    return proxy_request(url)

def proxy_request(url):
    try:
        resp = requests.request(
            method=request.method,
            url=url,
            headers=dict(request.headers),
            data=request.get_data(),
            cookies=request.cookies,
            allow_redirects=False,
            timeout=30
        )
        
        return resp.content, resp.status_code, resp.headers.items()
    
    except requests.exceptions.Timeout:
        return jsonify({'error': 'Service timeout'}), 504
    except requests.exceptions.ConnectionError:
        return jsonify({'error': 'Service unavailable'}), 503

# ========================================
# 4. PIPELINE CI/CD AVANÃ‡ADO
# ========================================

# .github/workflows/microservices-ci-cd.yml
name: Microservices CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository }}/

jobs:
  # ========================================
  # DETECTAR MUDANÃ‡AS EM SERVIÃ‡OS
  # ========================================
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      user-service: ${{ steps.changes.outputs.user-service }}
      product-service: ${{ steps.changes.outputs.product-service }}
      api-gateway: ${{ steps.changes.outputs.api-gateway }}
    steps:
    - uses: actions/checkout@v3
    - uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          user-service:
            - 'services/user-service/**'
          product-service:
            - 'services/product-service/**'
          api-gateway:
            - 'services/api-gateway/**'

  # ========================================
  # TESTES E BUILD PARALELO POR SERVIÃ‡O
  # ========================================
  build-user-service:
    needs: detect-changes
    if: needs.detect-changes.outputs.user-service == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: ğŸ§ª Testes do User Service
      run: |
        cd services/user-service
        pip install -r requirements.txt
        pytest tests/ --cov=. --cov-report=xml
    
    - name: ğŸ³ Build e Push User Service
      uses: docker/build-push-action@v4
      with:
        context: services/user-service
        push: true
        tags: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}

  build-product-service:
    needs: detect-changes
    if: needs.detect-changes.outputs.product-service == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: ğŸ§ª Testes do Product Service
      run: |
        cd services/product-service
        pip install -r requirements.txt
        pytest tests/ --cov=. --cov-report=xml
    
    - name: ğŸ³ Build e Push Product Service
      uses: docker/build-push-action@v4
      with:
        context: services/product-service
        push: true
        tags: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}product-service:${{ github.sha }}

  # ========================================
  # TESTES DE INTEGRAÃ‡ÃƒO
  # ========================================
  integration-tests:
    needs: [build-user-service, build-product-service]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: ğŸš€ Subir ambiente de teste
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30  # Aguardar serviÃ§os subirem
    
    - name: ğŸ§ª Executar testes de integraÃ§Ã£o
      run: |
        pytest tests/integration/ --verbose
    
    - name: ğŸ“Š Testes de carga com K6
      run: |
        docker run --rm -i grafana/k6 run - <tests/load/api-test.js

  # ========================================
  # ANÃLISE DE SEGURANÃ‡A
  # ========================================
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: ğŸ”’ Scan de vulnerabilidades
      uses: anchore/scan-action@v3
      with:
        image: ${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}
    
    - name: ğŸ›¡ï¸ AnÃ¡lise de cÃ³digo com CodeQL
      uses: github/codeql-action/analyze@v2

  # ========================================
  # DEPLOY STAGING
  # ========================================
  deploy-staging:
    if: github.ref == 'refs/heads/develop'
    needs: [integration-tests, security-scan]
    runs-on: ubuntu-latest
    environment: staging
    steps:
    - name: ğŸš€ Deploy para Staging
      run: |
        echo "Deploying to staging with GitOps..."
        # Atualizar manifesto no repositÃ³rio GitOps
        
  # ========================================
  # DEPLOY PRODUÃ‡ÃƒO COM CANARY
  # ========================================
  deploy-production:
    if: github.ref == 'refs/heads/main'
    needs: [integration-tests, security-scan]
    runs-on: ubuntu-latest
    environment: production
    steps:
    - name: ğŸ¯ Canary Deploy
      run: |
        # Deploy canÃ¡rio com 10% do trÃ¡fego
        kubectl patch deployment user-service \\
          -p '{"spec":{"template":{"spec":{"containers":[{"name":"user-service","image":"'${{ env.REGISTRY }}${{ env.IMAGE_PREFIX }}user-service:${{ github.sha }}'"}]}}}}'
        
        # Aguardar mÃ©tricas
        sleep 300
        
        # Se mÃ©tricas OK, deploy completo
        kubectl scale deployment user-service-canary --replicas=0

# ========================================
# 5. MONITORAMENTO AVANÃ‡ADO
# ========================================

# monitoring/prometheus-rules.yml
groups:
- name: ecommerce.rules
  rules:
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service {{ $labels.job }} is down"
      
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate on {{ $labels.service }}"
      
  - alert: HighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High latency on {{ $labels.service }}"

print("ğŸ¯ PROJETO DEVOPS Ã‰PICO:")
print("ğŸ—ï¸ 1. Arquitetura de microserviÃ§os")
print("ğŸ³ 2. ContainerizaÃ§Ã£o completa")
print("âš™ï¸ 3. CI/CD com deploy canÃ¡rio")
print("ğŸ§ª 4. Testes automatizados (unit + integration + load)")
print("ğŸ”’ 5. AnÃ¡lise de seguranÃ§a automÃ¡tica")
print("â˜ï¸ 6. Kubernetes com auto-scaling")
print("ğŸ“Š 7. Monitoramento full-stack")
print("ğŸš¨ 8. Alertas inteligentes")
print("ğŸ“ˆ 9. MÃ©tricas de negÃ³cio")
print("ğŸ”„ 10. GitOps para deploy")
print("")
print("ğŸ† ESTE Ã‰ O NÃVEL DE UM SENIOR DEVOPS ENGINEER!")
'''
        
        self.exemplo(codigo_projeto)
        
        print("\nğŸŠ CARACTERÃSTICAS DO PROJETO:")
        print("âœ… MicroserviÃ§os em Python/Flask")
        print("âœ… API Gateway para roteamento")
        print("âœ… Banco PostgreSQL por serviÃ§o")
        print("âœ… Redis para cache distribuÃ­do")
        print("âœ… Docker Compose para desenvolvimento")
        print("âœ… Kubernetes para produÃ§Ã£o")
        print("âœ… Pipeline CI/CD com GitHub Actions")
        print("âœ… Testes automatizados em 3 nÃ­veis")
        print("âœ… Deploy canÃ¡rio para zero downtime")
        print("âœ… Monitoramento com Prometheus/Grafana")
        print("âœ… Alertas inteligentes")
        print("âœ… Logs centralizados")
        print("âœ… MÃ©tricas de negÃ³cio")
        
        print("\nğŸš€ TECNOLOGIAS ENTERPRISE:")
        print("â€¢ ğŸ³ Docker & Docker Compose")
        print("â€¢ â˜¸ï¸ Kubernetes")
        print("â€¢ âš™ï¸ GitHub Actions")
        print("â€¢ ğŸ—ï¸ Terraform")
        print("â€¢ ğŸ“Š Prometheus & Grafana")
        print("â€¢ ğŸ” Jaeger (tracing)")
        print("â€¢ ğŸ“ ELK Stack (logs)")
        print("â€¢ ğŸ”’ OWASP ZAP (security)")
        print("â€¢ ğŸ§ª Jest & K6 (testing)")
        print("â€¢ ğŸŒ Nginx (load balancer)")
        
        # Registra conclusÃ£o do projeto
        self.complete_mini_project("Pipeline DevOps Completo - E-commerce Microservices")
        
        print("\nğŸ† PARABÃ‰NS! VocÃª dominou DevOps de nÃ­vel SENIOR!")
        print("ğŸ¯ Este projeto demonstra capacidade tÃ©cnica para:")
        print("â€¢ ğŸ’¼ Senior DevOps Engineer")
        print("â€¢ ğŸ—ï¸ Platform Engineer")
        print("â€¢ â˜ï¸ Cloud Architect")
        print("â€¢ ğŸ”§ Site Reliability Engineer (SRE)")
        
        self.pausar()
